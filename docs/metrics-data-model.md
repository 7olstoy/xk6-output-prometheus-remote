# k6 Time Series

We want to migrate to the time series data model for getting the benefits where we can efficiently identify the combination between a metric and the relative tags.

It introduces several benefits across the platform:

* It allows executing faster lookups and comparisons by a single value, the ID (hash) of the series.
* It reduces the storage by allocating just one time a possible combination (the time series) and referencing it in all other places. 
* It allows aggregating data by time series.
* It enables easier detection of high cardinality issues just by counting the entire unique data set of generated time series.
* It enables time series based outputs to simplify the integration's logic (e.g. Prometheus).

## Data model

#### Metrics and Series

* Metric (name, type)
* Time Series (metric, tags)
* Sample (timestamp, value, time series ref)
* Tag and TagSet (aka [k6/1831](https://github.com/grafana/k6/issues/1831))

```go
// This is the current k6 Metric polished from the Thresholds dependencies.
type Metric struct {
	Name     string
	Type     MetricType
	Contains ValueType
}

type Tag struct {
    Key, Value string
}

type TagSet []*Tag

type TimeSeries struct {
	ID uint64 // hash(metric+tags)
	MetricName string
	Tags   TagSet
}

type Sample struct {
        TimeSeries *TimeSeries
        Timestamp uint64
        Value float64
}
```

#### Open questions:

* Do we need the `TagSet` in the Sample or can we just simplify it as a `[]string` or `map[string]string` and delegate it in a centralized place to the `TagSet` association?
* Currently, the metric type is defined by the `metrics.Metric` but the same type handle Thresholds and Sink operation. Should the `TimeSeries` type depend on `Metric`? Or should we wait to split the Sink/Thresholds part in a different struct?

#### IDs

The series IDs are a `uint64` value generated by hashing the metric name and the tags' key-value pairs.

#### Sink

The sinks are implemented by metric types and they keep the series values up to date:

* Counter:  a monotonic increasing value
* Gauge: the latest value
* SparseHistogram: counters per dynamic ranges (buckets) - https://grafana.com/blog/2021/11/03/how-sparse-histograms-can-improve-efficiency-precision-and-mergeability-in-prometheus-tsdb

## Storage

#### Time Series database (aka tsdb)

We need to store all the time series generated from `k6` run during the execution so the other components (mostly the outputs) could query the storage for getting the value of the time series. It's expected to be in-memory and it should be concurrent-safe.

```go
type Repository interface {
    InsertSeries(TimeSeries) error
    GetSeriesByID(id uint64) (*TimeSeries, error)
}
```

#### TagMap

```go
type TagMap struct {
    m sync.Map // potentially something better
}
```

It creates a finite set of tags storing the pointer of Tags by its hash. In this way, it should reduce the used memory and the GC operations.

#### Open questions:

* Is the same structure by TagSet required? It could be useful in the case we need to compare a pair of TagSet, where we can just execute single access by hash instead of N comparisons.

#### Open questions:

* Do we require to identify the time series before invoking `metrics.PushIfNotDone`? So, does the sample require to reference the time series?

## metrics.Ingester

Ingester is responsible for resolving the time series and storing the pointer in the Sample then resolves the relationships between the time series and it sinks the relative metrics.

##### Example

In a `t0` where the status of the seen time series is:

```text
http_req_duration{status:200,method:GET}
http_req_duration{method:GET}
http_req_duration{status:200}
http_req_another_one{status:200}
```

The Ingester in the case of a collected Sample `http_req_duration{status:200,method:GET}` then it resolves the dependencies with the other seen time series in a unique set where it contains the following time series  `http_req_duration{status:200}` and `http_req_duration{method:GET}`. It can now resolve the relative Metric's Sinks and it invokes them passing the Sample's value.

## Known issues

* Name and URL tags: `k6` is tagging HTTP requests with the URL. It will create a high cardinality issue for the time series data model. This should be fixed by adding the possibility to not store all the tags as indexable, having the availability to set them as `metadata` and exclude them from the time series generation. An alternative workaround could be to exclude them from the default set of enabled tags.
* We need to keep all the data for the Trend type for computing the percentiles. We plan to migrate to some form of approximation (Sparse Histogram, OpenHistogram, T-Digest, etc..)

## Roadmap proposal

1. Add a simpler implementation in the Prometheus Output extension
2.  Collect feedback and re-iterate
3. Use it directly into the k6 core (two options):
   1. We could use the new model for some parts of the core and keep the old in parallel with the new model then gradually migrate the rest.
   2. Replace the entire data model in one shot

## Acceptance criteria

- [ ] Can the new model enable the Prometheus output integration?
- [ ] Can the new model enable cloud aggregation?
- [ ] Can the new model work with Thresholds?
- [ ] Is the memory footprint generated from the new model reduced? If not, is it acceptable?
- [ ] Is the CPUs usage generated from the new model reduced? If not, is it acceptable?
