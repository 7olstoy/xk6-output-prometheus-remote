# k6 Time Series

We want to introduce the time series concept to k6 for getting the benefit of efficiently identifying the combination between a metric and the relative tags.

A summary of the benefits it brings across the platform:

* It allows executing faster lookups and comparisons by a single value, the ID (hash) of the series.
* It reduces the storage by allocating just one time a possible combination (the time series) and referencing it in all other places. 
* It allows aggregating data by time series.
* It enables easier detection of high cardinality issues just by counting the entire unique data set of generated time series.
* It enables time series based outputs to simplify the integration's logic (e.g. Prometheus).

## Data model

#### Metrics and Series

* Metric (name, type)
* Time Series (metric, tags)
* Sample (timestamp, value, time series ref)
* Tag - (aka [k6/1831](https://github.com/grafana/k6/issues/1831))

```go
// This is the current k6 Metric polished from the Thresholds dependencies.
type Metric struct {
	Name     string
	Type     MetricType
	Contains ValueType
}

type Tag struct {
    Key, Value string
}

type TimeSeries struct {
	ID uint64 // hash(metric+tags)
	MetricName string
	Tags   []Tag
}

type Sample struct {
        TimeSeries *TimeSeries
        Timestamp uint64
        Value float64
}
```

> **Note**: Tag and Metric without Sink+Threholds are represented here just as a general overview of the potential final data model. Tag is to be considered as [k6/1831](https://github.com/grafana/k6/issues/1831) and it isn't expected to be addressed in the same iteration.

#### IDs

The series IDs are `uint64` values generated by hashing the metric name and the tags' key-value pairs.

#### Sink

The sinks are implemented by metric types and they keep the series values up to date:

* Counter:  a monotonic increasing value
* Gauge: the latest value
* SparseHistogram: counters per dynamic ranges (buckets) - https://grafana.com/blog/2021/11/03/how-sparse-histograms-can-improve-efficiency-precision-and-mergeability-in-prometheus-tsdb

## Storage

#### Time Series database (aka tsdb)

We need to store all the time series generated from `k6` run during the execution so the other components (mostly the outputs) could query the storage for getting the value of the time series. It's expected to be in-memory and it should be concurrent-safe.

```go
type Repository interface {
    InsertSeries(TimeSeries) error
    GetSeriesByID(id uint64) (*TimeSeries, error)
}
```

## Samples generation

The current sampling process is controlled by the `metrics.PushIfNotDone` method. All the actual callers should resolve the time series from the storage before push a new Sample, or in the event no one is found to create and insert.
It requires the dependency from the time series database for all the callers (e.g. executors, JavaScript modules).

## metrics.Ingester

Ingester is responsible for resolving the entire set of Sinks impacted from the ingested time series then it adds the Sample's value to the resolved Sinks.

##### Example

In a `t0` where the status of the seen time series is:

```text
http_req_duration{status:200,method:GET}
http_req_duration{method:GET}
http_req_duration{status:200}
http_req_another_one{status:200}
```

The Ingester in the case of a collected Sample `http_req_duration{status:200,method:GET}` then it resolves the dependencies with the other seen time series in a unique set where it contains the following time series  `http_req_duration{status:200}` and `http_req_duration{method:GET}`. It can now resolve the relative Metric's Sinks and it invokes them passing the Sample's value.

## Known issues

* Name and URL tags: `k6` is tagging HTTP requests with the URL. It will create a high cardinality issue for the time series data model. This should be fixed by adding the possibility to not store all the tags as indexable, having the availability to set them as `metadata` and exclude them from the time series generation. An alternative workaround could be to exclude them from the default set of enabled tags.
* We need to keep all the data for the Trend type for computing the percentiles. We plan to migrate to some form of approximation (Sparse Histogram, OpenHistogram, T-Digest, etc..)

## Acceptance criteria

- [ ] Can the new model enable the Prometheus output integration?
- [ ] Can the new model enable cloud aggregation?
- [ ] Can the new model work with Thresholds?
- [ ] Is the memory footprint generated from the new model reduced? If not, is it acceptable?
- [ ] Is the CPUs usage generated from the new model reduced? If not, is it acceptable?
